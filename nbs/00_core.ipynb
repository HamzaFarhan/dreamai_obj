{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# core\n",
    "\n",
    "> Core functionality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%nbdev_skip_test` not found.\n"
     ]
    }
   ],
   "source": [
    "#| hide\n",
    "\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.test import *\n",
    "\n",
    "%nbdev_skip_test\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hamza/anaconda3/envs/jbt3/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "\n",
    "from dreamai.core import *\n",
    "from dreamai.vision import *\n",
    "from dreamai.imports import *\n",
    "from dreamai_obj.imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "\n",
    "def obj_model():\n",
    "    return yolov5.load('yolov5s.pt')\n",
    "\n",
    "def obj_detect(model, img, conf=0.3, iou=0.45, agnostic=False, multi_label=False, max_det=1000):\n",
    "    \n",
    "    model.conf = conf\n",
    "    model.iou = iou\n",
    "    model.agnostic = agnostic\n",
    "    model.multi_label = multi_label\n",
    "    model.max_det = max_det\n",
    "    results = model(img, augment=True)\n",
    "    # print()\n",
    "    # print(results.names)\n",
    "    predictions = results.pred[0]\n",
    "    boxes = predictions[:,:4]\n",
    "    scores = predictions[:,4]\n",
    "    categories = predictions[:,5]\n",
    "    # print(f'\\ncategories: {categories}')\n",
    "    return boxes.detach().cpu(), [results.names[int(cat)] for cat in categories]\n",
    "\n",
    "def box_overlap(box1, box2, limit=0):\n",
    "    x1, y1, x2, y2 = box1\n",
    "    x3, y3, x4, y4 = box2\n",
    "    x_overlap = max(0, min(x2,x4) - max(x1,x3))\n",
    "    y_overlap = max(0, min(y2,y4) - max(y1,y3))\n",
    "    overlap = (x_overlap * y_overlap) > limit\n",
    "    return overlap\n",
    "\n",
    "def distance_to_camera(width, focal_len, pixel_width):\n",
    "    return (width * focal_len) / pixel_width\n",
    "\n",
    "def detect_obstacles_3(model, img, targets=[], alert=True, h_limit=1024, show=False, box_thicknes=7,\n",
    "                       avoidance_x=0, avoidance_y=0.5, avoidance_w=0.5, avoidance_h=0.5, obj_h_limit=0.5,\n",
    "                       conf=0.3, overlap_limit=0, color='red'):\n",
    "    \n",
    "    color = color_to_rgb(color)\n",
    "    img = copy.deepcopy(img)\n",
    "    h,w = get_hw(img)\n",
    "    if h > h_limit:\n",
    "        img = imutils.resize(img, height=h_limit)\n",
    "    h,w = get_hw(img)\n",
    "    if is_float(avoidance_h):\n",
    "        avoidance_h = int(h*avoidance_h)\n",
    "    if is_float(avoidance_w):\n",
    "        avoidance_w = int(w*avoidance_w)\n",
    "    if is_float(avoidance_x):\n",
    "        avoidance_x = int(w*avoidance_x)\n",
    "    if is_float(avoidance_y):\n",
    "        avoidance_y = int(h*avoidance_y)\n",
    "    if obj_h_limit is not None:\n",
    "        if is_float(obj_h_limit):\n",
    "            obj_h_limit = int(h*obj_h_limit)\n",
    "    else:\n",
    "        obj_h_limit = h\n",
    "    green = solid_color_img((avoidance_h, avoidance_w, 3), 'green', alpha=150)\n",
    "    red = solid_color_img_like(green, 'red', alpha=150)\n",
    "    # gx,gy = get_pos(green, img, [0,1.])\n",
    "    if show:\n",
    "        print('\\nIMAGE:\\n')\n",
    "        plt_show(paste_img(green, img, [avoidance_x,avoidance_y]))\n",
    "    found = False\n",
    "    boxes,cats = obj_detect(model, img, conf=conf)\n",
    "    if len(targets) == 0:\n",
    "        targets = cats\n",
    "    # print(f'{len(boxes)}, {len(cats)}')\n",
    "    cat_boxes = []\n",
    "    for box,cat in zip(boxes, cats):\n",
    "        if cat in targets:\n",
    "            # print(f'\\nBOX: {box}\\n')\n",
    "            # print(f'\\nCATEGORY: {cat}\\n')\n",
    "            x1, y1, x2, y2 = [int(x) for x in box]\n",
    "            bh = y2-y1\n",
    "            if bh > obj_h_limit:\n",
    "                continue\n",
    "            bw = x2-x1\n",
    "            c_area = bh*bw\n",
    "            box1 = [x1, y1, x2, y2]\n",
    "            cat_boxes.append(box1)\n",
    "            box2 = [avoidance_x, avoidance_y, avoidance_x+avoidance_w, avoidance_y+avoidance_h]\n",
    "            if not box_overlap(box1, box2, overlap_limit) and alert:\n",
    "                continue\n",
    "            if not found:\n",
    "                found = True\n",
    "                if show:\n",
    "                    print('\\nOBSTACLE(S) FOUND:\\n')\n",
    "            if show:\n",
    "                print(f'Area: {c_area}, x: {x1}, y: {y1}, bw: {bw}, bh: {bh}')\n",
    "            # try:\n",
    "            txt_y = y1 - 10 if y1 - 10 > 10 else y1 + 10\n",
    "            cv2.putText(img, cat, (x1, txt_y), cv2.FONT_HERSHEY_SIMPLEX, 0.65, color, 2)\n",
    "            cv2.rectangle(img, (x1,y1), (x2,y2), color, box_thicknes)\n",
    "            # except:\n",
    "                # pass\n",
    "            if show:\n",
    "                plt_show(paste_img(red, img, [avoidance_x,avoidance_y]))\n",
    "    if not found and show:\n",
    "        print('NO OBSTACLES FOUND')\n",
    "    if found and alert:\n",
    "        img = paste_img(red, img, [avoidance_x,avoidance_y])\n",
    "    elif alert:\n",
    "        img = paste_img(green, img, [avoidance_x,avoidance_y])\n",
    "    torch.cuda.empty_cache()\n",
    "    return img, cat_boxes\n",
    "\n",
    "def save_video(v, path='video.mp4', audio=True, codec='libx264',ffmpeg_path='/usr/bin/ffmpeg'):\n",
    "    \n",
    "    if type(v).__name__ == 'ProntoClip':\n",
    "        v = v.v\n",
    "    if 'Image' in type(v).__name__:\n",
    "        v.write_videofile(path,audio=audio,fps=v.fps, audio_codec='aac', bitrate=str(np.power(10, 6)),\n",
    "                          preset='ultrafast', verbose=False, threads=6, logger=None, codec=codec)\n",
    "    else:\n",
    "        try:\n",
    "            if not audio:\n",
    "                v = v.set_audio(None)\n",
    "            v.save(bitrate='10000000', output_file=path, ffmpeg_path=ffmpeg_path, codec=codec)\n",
    "        except:\n",
    "            v.write_videofile(path,audio=audio,fps=v.fps, audio_codec='aac', bitrate=str(np.power(10, 6)),\n",
    "                              preset='ultrafast', verbose=False, threads=6, logger=None, codec=codec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jbt3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
